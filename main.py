import cv2
import torch
torch.classes.__path__ = []

from ultralytics import YOLO
import base64
import os

import numpy as np


import requests
import streamlit as st
from PIL import Image
#from streamlit_image_coordinates import streamlit_image_coordinates as im_coordinates

def clahe(image):
    """
    CLAHE (Contrast Limited Adaptive Histogram Equalization) alkalmaz√°sa.
    """
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    clahe_image = clahe.apply(gray_image)
    return cv2.cvtColor(clahe_image, cv2.COLOR_GRAY2BGR)

# Load a model
model = YOLO("model.pt")

files = {
    "K√©p 1": os.path.join("img3", "1.jpg"),
    "K√©p 2": os.path.join("img3", "2.jpg"),
    "K√©p 3": os.path.join("img3", "3.jpg")
}

# Alkalmaz√°s c√≠m
st.set_page_config(page_title="YOLO Object Detection", page_icon="üî•")
st.title("YOLO Object Detection")
st.write("El≈ëfeldolgoz√°s: CLAHE (clipLimit=3.0, tileGridSize=(8, 8))")
st.write("A modell: XS")
st.write("Let√∂lthet≈ë k√©pek tesztel√©shez:")
cols = st.columns([1, 1, 1], gap="small")

for col, (label, path) in zip(cols, files.items()):
    with col:
        with open(path, "rb") as f:
            st.download_button(
                label=f"üì• {label}",
                data=f,
                file_name=os.path.basename(path),
                mime="image/png",
                use_container_width=False  # fontos, hogy ne ny√∫jtsa sz√©t
            )
# Itt add meg a GitHub repo-d URL-j√©t, ahol az img3 mappa van
github_url = "https://github.com/mecalis/fiok_streamlit/tree/main/img3"
st.markdown(f"[üëâ Nyisd meg az img3 mapp√°t a GitHubon az √∂sszes t√∂bbi k√©p√©rt!]({github_url})")
# Felt√∂lt√∂tt k√©p t√°rol√°sa
uploaded_image = st.file_uploader("T√∂lts fel egy k√©pet", type=["jpg", "png", "jpeg"])

def clear_images():
    if "image" in st.session_state:
        del st.session_state["image"]
    if "detected_image" in st.session_state:
        del st.session_state["detected_image"]
    uploaded_image_slot.empty()
    detected_image_slot.empty()
    detected_data_slot.empty()
    detected_speed_slot.empty()

st.button("Clear", on_click=clear_images)

# Helyek l√©trehoz√°sa k√©pek megjelen√≠t√©s√©hez
uploaded_image_slot = st.empty()
detected_image_slot = st.empty()
detected_data_slot = st.empty()
detected_speed_slot = st.empty()

if uploaded_image is not None:
    # Eredeti k√©p megjelen√≠t√©se
    image = Image.open(uploaded_image)
    uploaded_image_slot.image(image, caption="Felt√∂lt√∂tt k√©p", use_container_width=True)

    # K√©p ment√©se az √°llapotba
    st.session_state["image"] = image

    if st.button("Detect"):
        # YOLO detekci√≥ futtat√°sa
        image_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        clahe_img = clahe(image_bgr)
        pre_image = Image.fromarray(cv2.cvtColor(clahe_img, cv2.COLOR_BGR2RGB))

        results = model.predict(source = pre_image, conf = 0.7, iou = 0.85)
        #print("Predikci√≥k")
        #print(results)
        lines = []
        lines.append("Adatok: \n")
        text = ""
        for result in results:
            for box in result.boxes:

                x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box koordin√°t√°k
                if y1 > 250:
                    continue
                conf = box.conf[0].item()  # Konfidencia √©rt√©k
                cls = int(box.cls[0])  # Oszt√°ly index
                label = result.names[cls]  # Oszt√°ly neve
                print(label, cls, "conf:", conf, "x1, y1, x2, y2", x1, y1, x2, y2)
                lines.append(f"Label: {label}, cls: {cls}, conf:{conf:.2f}, x1, y1, x2, y2:{x1}, {y1}, {x2}, {y2} \n")
                # T√©glalap rajzol√°sa
                cv2.rectangle(clahe_img, (x1, y1), (x2, y2), (0, 255, 0), 2)

                # Felirat sz√∂vege
                text = f"{label} {conf:.2f}"

                # Sz√∂veg m√©rete √©s h√°tt√©r
                (w, h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
                cv2.rectangle(clahe_img, (x1, y1 - h + 25), (x1 + w, y1+25), (0, 255, 0), -1)
                cv2.putText(clahe_img, text, (x1, y1 + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)

        text = "\n".join(lines)

        result_image = results[0].orig_img
        detected_image = Image.fromarray(cv2.cvtColor(clahe_img, cv2.COLOR_BGR2RGB))

        #detected_image_path = os.path.join("output", uploaded_image.name)
        #detected_image = Image.open(detected_image_path)

        # Detekt√°lt k√©p megjelen√≠t√©se
        st.session_state["detected_image"] = detected_image
        detected_image_slot.image(detected_image, caption="Detekt√°lt k√©p", use_container_width =True)

        #Adatok ki√≠r√°sa
        #st.write("Adatok a detekci√≥ ut√°n:")

        detected_data_slot.write(f"{text}")
        detected_speed_slot.write(f"Sebess√©gek [ms]: {results[0].speed}. √Åltal√°ban <= ~100 ms. ")









